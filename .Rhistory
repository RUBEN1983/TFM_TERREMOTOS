ibex <- html_table(tmp[[4]])
ibex
ibex <- html_table(tmp[[5]])
ibex
url.ibex <- "http://www.bolsamadrid.es/esp/aspx/Mercados/Precios.aspx?indice=ESI100000000"
tmp <- read_html(url.ibex)
tmp <- html_nodes(tmp, "table")
tmp
sapply(tmp, function(x) dim(html_table(x, fill = TRUE)))
ibex <- html_table(tmp[[5]])
ibex
url.ibex <- "https://web.ua.es/es/urs/sismicidad/sismos-2017-alicante-y-provincias-limitrofes.html"
tmp <- read_html(url.ibex)
tmp <- html_nodes(tmp, "table")
tmp
sapply(tmp, function(x) dim(html_table(x, fill = TRUE)))
ibex <- html_table(tmp[[2]])
ibex
library(rjson)
install.packages(rjson)
install.packages("rjson")
library(rjson)
url <- 'http://someurl/data.json'
document <- fromJSON(file=url, method='C')
document <- fromJSON("C:/Users/Ruben/Desktop/query.json")
document <- fromJSON("C:/Users/Ruben/Desktop/events-2017-03-30T18_16_07.json")
document <- fromJSON("C:/Users/Ruben/Desktop/events-2017-04-10T18_49_01.json")
?geoJSON
??geoJSON
library(rjson)
document <- fromJSON("C:/Users/Ruben/Desktop/events-2017-04-10T18_49_01.json")
library(jsonlite)
document <- fromJSON("C:/Users/Ruben/Desktop/events-2017-04-10T18_49_01.json")
document
document <- read.table(document)
document$geometry$type
document$geometry$coordinates
document <- read.table(documents$geometry$coordinates)
document <- read.table(document$geometry$coordinates)
document <- read.table(document$geometry$coordinates)
library("rjson")
json_file <- "http://api.worldbank.org/country?per_page=10&region=OED&lendingtype=LNX&format=json"
json_data <- fromJSON(paste(readLines(json_file), collapse=""))
json_data
json_file
dim(json_data)
class(json_data)
json_data2 <- read.table(json_data[[2]])
json_data[[2]]
class(json_data[[2]])
class(json_data[[1]])
json_data[[1]]
document <- fromJSON("C:/Users/Ruben/Desktop/events-2017-04-10T18_51_19.json")
document
library(XML)
arch = "http://www.seismicportal.eu/fdsnws/event/1/query?start=2011-01-01&end=2011-01-02"
arch
doc <- xmlTreeParse(arch,getDTD=T,addAttributeNamespaces=T)
doc
len(doc)
length(doc)
doc$doc
length(doc$doc)
arriba = xmlRoot(doc)
arriba
names(arriba[[1]])
arriba$eventParameters
head(arriba)
length(arriba)
datos <- xmlToDataFrame(arch)
datos
dim(datos)
data <- xmlParse("http://forecast.weather.gov/MapClick.php?lat=29.803&lon=-82.411&FcstType=digitalDWML")
data <- xmlParse("https://forecast.weather.gov/MapClick.php?lat=29.803&lon=-82.411&FcstType=digitalDWML")
data <- xmlParse("http://forecast.weather.gov/MapClick.php?lat=29.803&lon=-82.411&FcstType=digitalDWML")
data <- xmlParse("http://www.seismicportal.eu/fdsnws/event/1/query?start=2011-01-01&end=2011-01-02")
xml_data <- xmlToList(data)
xml_data
class(xml_data)
xml_data$eventParameters$event$preferredOriginID
xml_data$eventParameters$.attrs
xml_data$eventParameters$.attrs[[1]]
xml_data$eventParameters$.attrs[[10]]
length(xml_data)
xml_data
xml_data$eventParameters$event$magnitude
xml_data$eventParameters$event$magnitude$mag
xml_data$eventParameters$event$magnitude$mag$value
xml_data$eventParameters$event$origin$latitude
xml_data$eventParameters$event
xml_data$eventParameters$event[1]
xml_data$eventParameters$event[2]
length (xml_data$eventParameters)
length (xml_data$eventParameters)
xml_data$eventParameters[10]
length (xml_data$eventParameters)
class (xml_data$eventParameters)
head (xml_data$eventParameters)
head (xml_data$eventParameters, n=+1L)
xml_data$eventParameters[10]$event$creationInfo
xml_data$eventParameters[10]$event$creationInfo$creationTime
extrae.hora <- function (x){
x$eventParameters$event$creationInfo$creationTime
}
extrae.hora(xml_data[0])
extrae.hora(xml_data)
length(xml_data$eventParameters)
lapply(xml_data$eventParameters,extrae.hora)
data <- xml_data$eventParameters
lapply(data,extrae.hora)
class(lista)
class(data)
lapply(data[3],extrae.hora)
extrae.hora <- function (x){
x$event$creationInfo$creationTime
}
extrae.hora(data)
extrae.hora(data[0])
extrae.hora(data[1])
extrae.hora(data[2])
extrae.hora(data[3])
extrae.hora <- function (x){
x$event$origin$time
}
extrae.hora(data[3])
extrae.hora(data[2])
extrae.hora(data[1])
extrae.hora <- function (x){
x$event$origin$time$value
}
extrae.hora(data[1])
extrae.hora(data)
extrae.hora(data[2])
extrae.hora(data[100])
lapply(data,extrae.hora)
sapply(data,extrae.hora)
tapply(data,extrae.hora)
lapply(data,extrae.hora)
is.recursive((data))
is.atomic((data))
class(data)
data[54]
mi.lista <- list(a=1:10, b=letters[1:3], cc=c(TRUE,FALSE,TRUE,FALSE))
mi.lista
length(mi.lista)
tapply(mi.lista,length)
lapply(mi.lista,length)
mi.lista[1]
sapply(mi.lista,length)
data[0]
data[1]
garbanzo <- lapply(data,extrae.hora)
length(mi.lista[1])
length(mi.lista[2])
mi.lista[1]
length(mi.lista[3])
length(mi.lista)
length(mi.lista[1][1])
sapply(mi.lista,length)
mi.lista[1][6]
mi.lista[1]
mi.lista[[1]]
mi.lista[[1]][6]
garbanzo <- lapply(data,class)
garbanzo
length(garbanzo)
data <- xml_data$eventParameters$event
garbanzo <- lapply(data,class)
length(garbanzo)
garbanzo
extrae.hora <- function (x){
x$origin$time$value
}
extrae.hora(data[100])
extrae.hora(data)
extrae.hora <- function (x){
print x$origin$time$value
}
extrae.hora <- function (x){
print (x$origin$time$value)
}
garbanzo <- lapply(data,class)
garbanzo
garbanzo <- lapply(data,extrae.hora)
data[1]
data[2]
data[3]
len(data)
length(data)
data
data[5]
sapply(mi.lista,length)
garbanzo <- lapply(data,extrae.hora)
extrae.hora <- function (x){
hora <- x$event$origin$time$value
hora
}
garbanzo <- lapply(data,extrae.hora)
xml_data$eventParameters[10]$event$origin$time$value
xml_data$eventParameters[123]$event$origin$time$value
extrae.hora <- function (x){
hora <- x[["event"]][["origin"]][["time"]][["value"]]
hora
}
garbanzo <- lapply(data,extrae.hora)
extrae.hora(data[2])
print hora
extrae.hora <- function (x){
hora <- x[["event"]][["origin"]][["time"]][["value"]]
print (hora)
}
extrae.hora(data)
extrae.hora(data[1])
extrae.hora(data[2])
extrae.hora(data[34])
extrae.hora <- function (x){
hora <- x[["event"]]
print (hora)
}
extrae.hora(data[34])
extrae.hora <- function (x){
hora <- x$event
print (hora)
}
extrae.hora(data[34])
extrae.hora <- function (x){
x$event
}
extrae.hora(data[34])
data
data[34]
data <- xml_data$eventParameters
data[34]
extrae.hora <- function (x){
x[["event"]]
}
extrae.hora(data[34])
extrae.hora <- function (x){
x[["event"]][["origin"]]
}
extrae.hora(data[34])
x[["event"]][["origin"]][["time"]]
extrae.hora <- function (x){
x[["event"]][["origin"]][["time"]]
}
extrae.hora(data[34])
extrae.hora <- function (x){
x[["event"]][["origin"]][["time"]][["value"]]
}
extrae.hora(data[34])
garbanzo <- lapply(data,extrae.hora)
extrae.hora(data[34])
print (data[x]$event$origin$time$value)
for x in data{print (data[x]$event$origin$time$value)}
for x in data: {print (data[x]$event$origin$time$value)}
for (x in data): {print (data[x]$event$origin$time$value)}
for (x in data) {print (data[x]$event$origin$time$value)}
for (x in 1:x) {print (data[x]$event$origin$time$value)}
length(data)
for (x in 1:length(data)) {print (data[x]$event$origin$time$value)}
class(xml)
class(xml_data)
length(xml_data)
length(xml_data$eventParameters)
garbanzo <- lapply(xml_data$eventParameters,extrae.hora)
x[["event"]]
extrae.hora <- function (x){
x[["event"]]
}
garbanzo <- lapply(xml_data$eventParameters,extrae.hora)
library(XML)
library(zoo)
install.packages("zoo")
library(zoo)
mainURL <- 'http://www.tiempodiario.com'
radURL <- 'http://www.tiempodiario.com/radiacion/'
days <- seq(as.POSIXct('2010-12-05'), as.POSIXct('2012-10-28'), by='day')
for (i in seq_along(days)){
day <- days[i]
dayURL <- paste(radURL, format(day, '%Y/%m/%d'), '/', sep='')
## Obtengo el contenido HTML de la página del día en cuestión
content <- htmlParse(dayURL, encoding='utf8')
## y extraigo los enlaces a cada estación para ese día
links <- xpathSApply(content, "//a/@href")
linksData <- links[grep('radiacion-estacion', links)]
## Los nombres de las estaciones están escritos en los encabezados H2
h2 <- xpathSApply(content, "//h2")
namesStations <- sapply(h2[-1], function(s){
val <- xmlValue(s)
substr(val, 10, nchar(val))
})
## pero sus códigos de identificación están en los enlaces correspondientes
idStation <- strsplit(linksData, '/')
idStations <- sapply(idStation, function(x)x[4])
dayStationURL <- paste(mainURL, linksData, sep='')
## Accedo a la página de cada estación para ese día
zList <- lapply(dayStationURL, function(ds){
print(ds)
## Obtengo el contenido HTML de la página
content <- htmlParse(ds, encoding='utf8')
## y extraigo las tablas
tabs <- readHTMLTable(content, header=TRUE)
## Cada tabla codifica el índice temporal en la primera
## columna. A pesar de usar header=TRUE, la primera fila
## contiene el nombre las columnas. De ahí que tenga que usar
## -1 en el indexado.
time <- tabs[[1]][-1,1]
dayTime <- format(as.POSIXct(paste(day, time)), '%Y-%m-%d %H:%M')
## El nombre de la variable de cada tabla está codificado en
## los encabezados H2
h2 <- getNodeSet(content, '//h2')
tabLabels <- sapply(h2, xmlValue)
## Sólo me quedaré con las radiación difusa, directa y global
radVars <- c('Radiación Difusa (DF)',
'Radiación Directa (DT)',
'Radiación Global (GL)')
whichTabs <- which(tabLabels %in% radVars)
## Extraigo la información de las tablas seleccionadas. Dado
## que la primera fila contiene los nombres de las columnas,
## todo el contenido es leído como un "factor". De ahí que
## tenga que usar la conversión as.character y después
## as.numeric.
dat <- sapply(tabs[whichTabs],
function(tab)as.numeric(as.character(tab[-1, 2])))
## Finalmente, si todo ha ido bien, construyo un objeto zoo
## para almacenar la serie temporal de esta estación para este
## día. Si algo no ha funcionado obtendré NULL.
if (length(dat) > 0 & !is.list(dat)) {
z <- zoo(dat, as.POSIXct(dayTime))
names(z) <- tabLabels[whichTabs]
} else {
z <- NULL
}
z
})
## El resultado de lapply será una lista de objetos zoo, uno
## para cada estación. Pongo los nombres de las estaciones a
## cada componente de esta lista y grabo el resultado como un
## fichero RData.
names(zList) <- make.names(namesStations)
save(zList, file=paste(day, 'RData', sep='.'))
## Este código se repetirá para cada día, de forma que obtendré
## un conjunto de ficheros RData, uno por día. Cada uno de ellos
## contiene una lista de zoo's, correspondiendo cada componente
## de la lista a una estación de medida.
}
url.ibex <- "http://seismicportal.eu/"
tmp <- read_html(url.ibex)
??read_html
install.packages("xml2")
library(xml2)
url.ibex <- "http://seismicportal.eu/"
tmp <- read_html(url.ibex)
tmp <- html_nodes(tmp, "table")
library(rvest)
tmp <- html_nodes(tmp, "table")
tmp
require(xml2)
data <- xmlParse("http://www.seismicportal.eu/fdsnws/event/1/query?start=2011-01-01&end=2011-01-02")
data
class(data)
xml_data <- xmlToDataFrame(data)
xml_data
dim(xml_data)
xml_data <- xmlToS4(data)
data <- xmlParse("http://www.seismicportal.eu/fdsnws/event/1/query?start=2011-01-01&end=2011-01-02")
xml_data <- xmlToS4(data)
xml_data <- xmlTextNode(data)
xml_data <- xmlToList(data)
xml_data$eventParameters[1]
xml_data$eventParameters[2]
readLines(xml_data[1])
readLines(xml_data[[1]])
dataframe <- xmlToDataFrame(xml_data$eventParameters$event)
xml_data$eventParameters[2]
xml_data$eventParameters[2]$event
class(xml_data$eventParameters[2]$event)
install.packages("dummies")
library(dummies)
library(ggplot2)
install.packages("ggplot2")
library(dummies)
library(ggplot2)
coches=mtcars # Base de datos ejemplo en R
coches
str(coches)
head(coches)
summary(coches)
modelo_bruto=lm(mpg~.,data=coches) ##Regresion lineal
summary(modelo_bruto)
write.table(coches,"coches.csv", sep = ";")
cor(coches)
step(modelo_bruto,direction = "backward",trace=1)
modelo1=lm(mpg~cyl,data=coches)
summary(modelo1)
modelo2=lm(mpg~disp,data=coches)
summary(modelo2)
modelo3=lm(mpg~hp,data=coches)
summary(modelo3)
modelo4=lm(mpg~drat,data=coches)
summary(modelo4)
modelo5=lm(mpg~wt,data=coches)
summary(modelo5)
modelo6=lm(mpg~qsec,data=coches)
summary(modelo6)
modelo7=lm(mpg~vs,data=coches)
summary(modelo7)
modelo8=lm(mpg~am,data=coches)
summary(modelo8)
modelo9=lm(mpg~gear,data=coches)
summary(modelo9)
modelo10=lm(mpg~carb,data=coches)
summary(modelo10)
cor(coches)
modelo11=lm(mpg~  wt+qsec+am,data=coches) ##las que tengan mas correlacion con el target, en este caso mpg, usamos step backward para sacar los valores
summary(modelo11)
PCA<-prcomp(coches[,-c(1)],scale. = TRUE) ##Para sacar cuanto aporta cada variable, es como el codo
PCA
summary(PCA)
plot(PCA)
cor(coches)
cor(PCA$x)
biplot(PCA)
PCA$rotation
coches$PCA1=PCA$x[,1]
coches$PCA2=PCA$x[,2]
coches$PCA3=PCA$x[,3]
coches
modelo_PCA=lm(mpg~PCA1,data=coches)
summary(modelo_PCA)
modelo_PCA=lm(mpg~PCA$x,data=coches)
summary(modelo_PCA)
modelo_PCA=lm(mpg~PCA1+PCA3,data=coches)
summary(modelo_PCA)
biplot(PCA,choices=c(1,3))
coches=mtcars # Base de datos ejemplo en R
coches
str(coches)
head(coches)
summary(coches)
modelo_bruto=lm(mpg~.,data=coches) ##Regresion lineal
summary(modelo_bruto)
write.table(coches,"coches.csv", sep = ";")
cor(coches)
step(modelo_bruto,direction = "backward",trace=1)
modelo1=lm(mpg~cyl,data=coches)
summary(modelo1)
head(coches)
modelo2=lm(mpg~disp,data=coches)
summary(modelo2)
modelo3=lm(mpg~hp,data=coches)
summary(modelo3)
modelo4=lm(mpg~drat,data=coches)
summary(modelo4)
modelo5=lm(mpg~wt,data=coches)
summary(modelo5)
modelo6=lm(mpg~qsec,data=coches)
summary(modelo6)
modelo7=lm(mpg~vs,data=coches)
summary(modelo7)
modelo8=lm(mpg~am,data=coches)
summary(modelo8)
modelo9=lm(mpg~gear,data=coches)
summary(modelo9)
modelo10=lm(mpg~carb,data=coches)
summary(modelo10)
cor(coches)
modelo11=lm(mpg~  wt+cyl+disp,data=coches) ##las que tengan mas correlacion con el target, en este caso mpg, usamos step backward para sacar los valores
summary(modelo11)
modelo11=lm(mpg~  wt+qsec+am,data=coches) ##las que tengan mas correlacion con el target, en este caso mpg, usamos step backward para sacar los valores
summary(modelo11)
PCA<-prcomp(coches[,-c(1)],scale. = TRUE) ##Para sacar cuanto aporta cada variable, es como el codo
PCA
summary(PCA)
plot(PCA)
cor(coches)
cor(PCA$x)
biplot(PCA)
PCA$rotation
PCA$x
coches$PCA1=PCA$x[,1]
coches$PCA2=PCA$x[,2]
coches$PCA3=PCA$x[,3]
coches
modelo_PCA=lm(mpg~PCA1,data=coches)
summary(modelo_PCA)
modelo_PCA=lm(mpg~PCA$x,data=coches)
summary(modelo_PCA)
modelo_PCA=lm(mpg~PCA1+PCA3,data=coches)
summary(modelo_PCA)
biplot(PCA,choices=c(1,3))
library(ggplot2)
library(effects)
library(plyr)
load("data/samsungData.rda")
install.packages("effects")
library(ggplot2)
library(effects)
library(plyr)
load("data/samsungData.rda")
str(samsungData)
samsungData <- load("data/samsungData.rda")
install.packages("ggmap")
library(ggmap)
library(ggplot2)
unizar <- geocode('Plaza de la Escandalera, Oviedo', source = "google")
unizar         # coordenadas de Plaza de la Escandalera, Oviedo
unizar <- geocode('40.0,40.0', source = "google")
dir()
setwd("C:/Users/Ruben/Desktop/Master KSCHOOL/TFM_TERREMOTOS/")
dir()
dir()
